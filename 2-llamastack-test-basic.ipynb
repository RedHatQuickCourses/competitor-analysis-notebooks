{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c539b31c-c247-4327-ac08-5aee9659e4fa",
   "metadata": {},
   "source": [
    "# Llama Stack API Testing\n",
    "\n",
    "This notebook demonstrates how to connect to a Llama Stack server and perform basic operations using the **Llama Stack API**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0c611-86b3-497a-9ea0-c6925059c319",
   "metadata": {},
   "source": [
    "Let's start by querying the Llama Stack server and check if it is healthy and ready to accept requests. First we need to install the `llama-stack` client using `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c377b52-6d0a-4361-b7be-8f0be0e48a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-stack-client==0.3.0\n",
      "  Downloading llama_stack_client-0.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (4.10.0)\n",
      "Collecting click (from llama-stack-client==0.3.0)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from llama-stack-client==0.3.0)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fire (from llama-stack-client==0.3.0)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (0.28.1)\n",
      "Collecting pandas (from llama-stack-client==0.3.0)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (3.0.52)\n",
      "Collecting pyaml (from llama-stack-client==0.3.0)\n",
      "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from llama-stack-client==0.3.0)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (2.32.5)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (1.3.1)\n",
      "Collecting termcolor (from llama-stack-client==0.3.0)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting tqdm (from llama-stack-client==0.3.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client==0.3.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->llama-stack-client==0.3.0) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.3.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama-stack-client==0.3.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama-stack-client==0.3.0) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->llama-stack-client==0.3.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->llama-stack-client==0.3.0)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->llama-stack-client==0.3.0)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas->llama-stack-client==0.3.0)\n",
      "  Downloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama-stack-client==0.3.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-stack-client==0.3.0)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-stack-client==0.3.0)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-stack-client==0.3.0) (1.17.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama-stack-client==0.3.0) (0.2.13)\n",
      "Requirement already satisfied: PyYAML in /opt/app-root/lib64/python3.12/site-packages (from pyaml->llama-stack-client==0.3.0) (6.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama-stack-client==0.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama-stack-client==0.3.0) (2.5.0)\n",
      "Downloading llama_stack_client-0.3.0-py3-none-any.whl (425 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m165.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m317.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m250.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Downloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-inspection, tqdm, termcolor, pydantic-core, pyaml, numpy, mdurl, distro, click, annotated-types, pydantic, pandas, markdown-it-py, fire, rich, llama-stack-client\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [llama-stack-client]lama-stack-client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 click-8.3.1 distro-1.9.0 fire-0.7.1 llama-stack-client-0.3.0 markdown-it-py-4.0.0 mdurl-0.1.2 numpy-2.4.0 pandas-2.3.3 pyaml-25.7.0 pydantic-2.12.5 pydantic-core-2.41.5 pytz-2025.2 rich-14.2.0 termcolor-3.3.0 tqdm-4.67.1 typing-inspection-0.4.2 tzdata-2025.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-stack-client==0.3.0 rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa57d0c0-b6ab-4543-ab17-f41b9359a0d1",
   "metadata": {},
   "source": [
    "Now, import the `LlamaStackClient` class, and set the base URL of the Llamastack server (You can get the URL by running `oc get svc -n competitor-analysis`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9748377-f83d-4711-abda-9718bd35bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import LlamaStackClient\n",
    "import rich\n",
    "\n",
    "# For access from Notebooks within the cluster\n",
    "LS_URL = \"http://llama-stack-dist-service:8321\"\n",
    "\n",
    "# For access from Notebooks external to the cluster, use the route URL instead (oc get route -n competitor-analysis)\n",
    "#LS_URL = \"https://llama-stack-ext-competitor-analysis.apps.ocp.sx7qw.sandbox2219.opentlc.com/\"\n",
    "\n",
    "# Initialize the client\n",
    "client = LlamaStackClient(base_url=LS_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacecac9-05d1-49a1-9f2d-598606c72f48",
   "metadata": {},
   "source": [
    "List the models available in this Llama Stack instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ae7b13-286e-43be-85fc-cff2437e76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llama-stack-dist-service:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">identifier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference/granite-3-3-8b-instruct'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_resource_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'granite-3-3-8b-instruct'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">identifier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'granite-embedding-125m'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_dimension'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768.0</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sentence-transformers'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_resource_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ibm-granite/granite-embedding-125m-english'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">identifier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sentence-transformers/nomic-ai/nomic-embed-text-v1.5'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_dimension'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">768.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'default_configured'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api_model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sentence-transformers'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_resource_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'nomic-ai/nomic-embed-text-v1.5'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">model_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33midentifier\u001b[0m=\u001b[32m'vllm-inference/granite-3-3-8b-instruct'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mapi_model_type\u001b[0m=\u001b[32m'llm'\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'vllm-inference'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "        \u001b[33mprovider_resource_id\u001b[0m=\u001b[32m'granite-3-3-8b-instruct'\u001b[0m,\n",
       "        \u001b[33mmodel_type\u001b[0m=\u001b[32m'llm'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33midentifier\u001b[0m=\u001b[32m'granite-embedding-125m'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'embedding_dimension'\u001b[0m: \u001b[1;36m768.0\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mapi_model_type\u001b[0m=\u001b[32m'embedding'\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'sentence-transformers'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "        \u001b[33mprovider_resource_id\u001b[0m=\u001b[32m'ibm-granite/granite-embedding-125m-english'\u001b[0m,\n",
       "        \u001b[33mmodel_type\u001b[0m=\u001b[32m'embedding'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33midentifier\u001b[0m=\u001b[32m'sentence-transformers/nomic-ai/nomic-embed-text-v1.5'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'embedding_dimension'\u001b[0m: \u001b[1;36m768.0\u001b[0m, \u001b[32m'default_configured'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mapi_model_type\u001b[0m=\u001b[32m'embedding'\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'sentence-transformers'\u001b[0m,\n",
       "        \u001b[33mtype\u001b[0m=\u001b[32m'model'\u001b[0m,\n",
       "        \u001b[33mprovider_resource_id\u001b[0m=\u001b[32m'nomic-ai/nomic-embed-text-v1.5'\u001b[0m,\n",
       "        \u001b[33mmodel_type\u001b[0m=\u001b[32m'embedding'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "rich.print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f00c41-1ba7-4e0b-8cac-baa3fb617806",
   "metadata": {},
   "source": [
    "Now, list the providers available in this Llama Stack instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a089a8-b23e-4992-a5ef-fc6b46be4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llama-stack-dist-service:8321/v1/providers \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProviderInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'inference'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'url'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096.0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'api_token'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'********'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tls_verify'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">health</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Not Implemented'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provider does not implement health check'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'remote::vllm'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProviderInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'inference'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">health</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Not Implemented'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provider does not implement health check'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sentence-transformers'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'inline::sentence-transformers'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ProviderInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">api</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'vector_io'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">config</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'db_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/app-root/src/.llama/distributions/rh/milvus.db'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'kvstore'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'sqlite'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'namespace'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'db_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/opt/app-root/src/.llama/distributions/rh/milvus_registry.db'</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">health</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Not Implemented'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provider does not implement health check'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'milvus'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">provider_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'inline::milvus'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mProviderInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mapi\u001b[0m=\u001b[32m'inference'\u001b[0m,\n",
       "        \u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'url'\u001b[0m: \n",
       "\u001b[32m'https://granite-3-3-8b-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1'\u001b[0m,\n",
       "            \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m4096.0\u001b[0m,\n",
       "            \u001b[32m'api_token'\u001b[0m: \u001b[32m'********'\u001b[0m,\n",
       "            \u001b[32m'tls_verify'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mhealth\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'status'\u001b[0m: \u001b[32m'Not Implemented'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Provider does not implement health check'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'vllm-inference'\u001b[0m,\n",
       "        \u001b[33mprovider_type\u001b[0m=\u001b[32m'remote::vllm'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mProviderInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mapi\u001b[0m=\u001b[32m'inference'\u001b[0m,\n",
       "        \u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mhealth\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'status'\u001b[0m: \u001b[32m'Not Implemented'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Provider does not implement health check'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'sentence-transformers'\u001b[0m,\n",
       "        \u001b[33mprovider_type\u001b[0m=\u001b[32m'inline::sentence-transformers'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mProviderInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mapi\u001b[0m=\u001b[32m'vector_io'\u001b[0m,\n",
       "        \u001b[33mconfig\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'db_path'\u001b[0m: \u001b[32m'/opt/app-root/src/.llama/distributions/rh/milvus.db'\u001b[0m,\n",
       "            \u001b[32m'kvstore'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'type'\u001b[0m: \u001b[32m'sqlite'\u001b[0m,\n",
       "                \u001b[32m'namespace'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[32m'db_path'\u001b[0m: \u001b[32m'/opt/app-root/src/.llama/distributions/rh/milvus_registry.db'\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mhealth\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'status'\u001b[0m: \u001b[32m'Not Implemented'\u001b[0m, \u001b[32m'message'\u001b[0m: \u001b[32m'Provider does not implement health check'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[33mprovider_id\u001b[0m=\u001b[32m'milvus'\u001b[0m,\n",
       "        \u001b[33mprovider_type\u001b[0m=\u001b[32m'inline::milvus'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... and 15 more providers\n"
     ]
    }
   ],
   "source": [
    "providers = client.providers.list()\n",
    "rich.print(providers[:3])  # Print only first 3 providers\n",
    "print(f\"\\n... and {len(providers) - 3} more providers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c3d9b-de8b-45a1-91fe-c78323e85f00",
   "metadata": {},
   "source": [
    "## Chat Completion (OpenAI Compatible API)\n",
    "\n",
    "In the latest versions of Llama Stack, use `client.chat.completions.create()` instead of the deprecated `client.inference.chat_completion()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17244c8b-11a3-477f-ace4-54222899e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: vllm-inference/granite-3-3-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llama-stack-dist-service:8321/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-baac5768b21648b7a58279412c2289e7'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChatCompletionChoice</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChatCompletionChoiceMessageOpenAIAssistantMessageParam</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The capital of Mongolia is Ulaanbaatar, a city that serves as the political, economic, and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cultural hub of the country. Ulaanbaatar is located in the north-central part of Mongolia and is the largest city </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in the nation, with a population of over 1.4 million people (as of 2021 estimates). It has a rich history, blending</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional Mongolian culture with modern urban developments. The city is home to essential landmarks, such as the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Genghis Khan Statue Complex, the National Museum of Mongolia, and Sukhbaatar Square, which has historical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significance as the site where Mongolia declared independence from China in 1921.\\n\\nUlaanbaatar is also known for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiencing extreme seasonal temperature variations, with long, cold winters and short, mild summers. The city </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">faces environmental challenges related to air pollution, primarily due to the extensive use of coal for heating </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">during winter. Nonetheless, Ulaanbaatar remains a vital center for commerce, education, and tourism in Mongolia. If</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">you have any more questions about Mongolia or Ulaanbaatar, please feel free to ask!'</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">stop_reason</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1767873312</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'granite-3-3-8b-instruct'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OpenAIChatCompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">280</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">348</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">prompt_logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">kv_transfer_params</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">metrics</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trace_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2d95a6605ca715d8d8c0a17809625a9f'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'span_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a0b5d5381b94b16d'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2026-01-08T11:55:23.186773Z'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference/granite-3-3-8b-instruct'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">68</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'unit'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tokens'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trace_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2d95a6605ca715d8d8c0a17809625a9f'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'span_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a0b5d5381b94b16d'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2026-01-08T11:55:23.186799Z'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference/granite-3-3-8b-instruct'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">280</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'unit'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tokens'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trace_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2d95a6605ca715d8d8c0a17809625a9f'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'span_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a0b5d5381b94b16d'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'timestamp'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2026-01-08T11:55:23.186805Z'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference/granite-3-3-8b-instruct'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'provider_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'vllm-inference'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'metric'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'value'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">348</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'unit'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'tokens'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mOpenAIChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-baac5768b21648b7a58279412c2289e7'\u001b[0m,\n",
       "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mOpenAIChatCompletionChoice\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
       "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
       "            \u001b[33mmessage\u001b[0m=\u001b[1;35mOpenAIChatCompletionChoiceMessageOpenAIAssistantMessageParam\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "                \u001b[33mcontent\u001b[0m=\u001b[32m'The capital of Mongolia is Ulaanbaatar, a city that serves as the political, economic, and\u001b[0m\n",
       "\u001b[32mcultural hub of the country. Ulaanbaatar is located in the north-central part of Mongolia and is the largest city \u001b[0m\n",
       "\u001b[32min the nation, with a population of over 1.4 million people \u001b[0m\u001b[32m(\u001b[0m\u001b[32mas of 2021 estimates\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. It has a rich history, blending\u001b[0m\n",
       "\u001b[32mtraditional Mongolian culture with modern urban developments. The city is home to essential landmarks, such as the \u001b[0m\n",
       "\u001b[32mGenghis Khan Statue Complex, the National Museum of Mongolia, and Sukhbaatar Square, which has historical \u001b[0m\n",
       "\u001b[32msignificance as the site where Mongolia declared independence from China in 1921.\\n\\nUlaanbaatar is also known for \u001b[0m\n",
       "\u001b[32mexperiencing extreme seasonal temperature variations, with long, cold winters and short, mild summers. The city \u001b[0m\n",
       "\u001b[32mfaces environmental challenges related to air pollution, primarily due to the extensive use of coal for heating \u001b[0m\n",
       "\u001b[32mduring winter. Nonetheless, Ulaanbaatar remains a vital center for commerce, education, and tourism in Mongolia. If\u001b[0m\n",
       "\u001b[32myou have any more questions about Mongolia or Ulaanbaatar, please feel free to ask!'\u001b[0m,\n",
       "                \u001b[33mname\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mannotations\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "                \u001b[33mreasoning_content\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[33mstop_reason\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1767873312\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[32m'granite-3-3-8b-instruct'\u001b[0m,\n",
       "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
       "    \u001b[33musage\u001b[0m=\u001b[1;35mOpenAIChatCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m280\u001b[0m,\n",
       "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m68\u001b[0m,\n",
       "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m348\u001b[0m,\n",
       "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mservice_tier\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mprompt_logprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mkv_transfer_params\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[33mmetrics\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trace_id'\u001b[0m: \u001b[32m'2d95a6605ca715d8d8c0a17809625a9f'\u001b[0m,\n",
       "            \u001b[32m'span_id'\u001b[0m: \u001b[32m'a0b5d5381b94b16d'\u001b[0m,\n",
       "            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'2026-01-08T11:55:23.186773Z'\u001b[0m,\n",
       "            \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_id'\u001b[0m: \u001b[32m'vllm-inference/granite-3-3-8b-instruct'\u001b[0m, \u001b[32m'provider_id'\u001b[0m: \u001b[32m'vllm-inference'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'metric'\u001b[0m,\n",
       "            \u001b[32m'metric'\u001b[0m: \u001b[32m'prompt_tokens'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[1;36m68\u001b[0m,\n",
       "            \u001b[32m'unit'\u001b[0m: \u001b[32m'tokens'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trace_id'\u001b[0m: \u001b[32m'2d95a6605ca715d8d8c0a17809625a9f'\u001b[0m,\n",
       "            \u001b[32m'span_id'\u001b[0m: \u001b[32m'a0b5d5381b94b16d'\u001b[0m,\n",
       "            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'2026-01-08T11:55:23.186799Z'\u001b[0m,\n",
       "            \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_id'\u001b[0m: \u001b[32m'vllm-inference/granite-3-3-8b-instruct'\u001b[0m, \u001b[32m'provider_id'\u001b[0m: \u001b[32m'vllm-inference'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'metric'\u001b[0m,\n",
       "            \u001b[32m'metric'\u001b[0m: \u001b[32m'completion_tokens'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[1;36m280\u001b[0m,\n",
       "            \u001b[32m'unit'\u001b[0m: \u001b[32m'tokens'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trace_id'\u001b[0m: \u001b[32m'2d95a6605ca715d8d8c0a17809625a9f'\u001b[0m,\n",
       "            \u001b[32m'span_id'\u001b[0m: \u001b[32m'a0b5d5381b94b16d'\u001b[0m,\n",
       "            \u001b[32m'timestamp'\u001b[0m: \u001b[32m'2026-01-08T11:55:23.186805Z'\u001b[0m,\n",
       "            \u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_id'\u001b[0m: \u001b[32m'vllm-inference/granite-3-3-8b-instruct'\u001b[0m, \u001b[32m'provider_id'\u001b[0m: \u001b[32m'vllm-inference'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'metric'\u001b[0m,\n",
       "            \u001b[32m'metric'\u001b[0m: \u001b[32m'total_tokens'\u001b[0m,\n",
       "            \u001b[32m'value'\u001b[0m: \u001b[1;36m348\u001b[0m,\n",
       "            \u001b[32m'unit'\u001b[0m: \u001b[32m'tokens'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Answer: The capital of Mongolia is Ulaanbaatar, a city that serves as the political, economic, and cultural hub of the country. Ulaanbaatar is located in the north-central part of Mongolia and is the largest city in the nation, with a population of over 1.4 million people (as of 2021 estimates). It has a rich history, blending traditional Mongolian culture with modern urban developments. The city is home to essential landmarks, such as the Genghis Khan Statue Complex, the National Museum of Mongolia, and Sukhbaatar Square, which has historical significance as the site where Mongolia declared independence from China in 1921.\n",
      "\n",
      "Ulaanbaatar is also known for experiencing extreme seasonal temperature variations, with long, cold winters and short, mild summers. The city faces environmental challenges related to air pollution, primarily due to the extensive use of coal for heating during winter. Nonetheless, Ulaanbaatar remains a vital center for commerce, education, and tourism in Mongolia. If you have any more questions about Mongolia or Ulaanbaatar, please feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Get the LLM model for inference\n",
    "inference_model_id = next(m.identifier for m in models if m.model_type == \"llm\")\n",
    "print(f\"Using model: {inference_model_id}\")\n",
    "\n",
    "prompt = \"What is the capital of Mongolia?\"\n",
    "\n",
    "# LlamaStack 0.3.0: Use OpenAI-compatible chat.completions.create() API\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=inference_model_id  # Note: 'model' not 'model_id'\n",
    ")\n",
    "rich.print(response)\n",
    "\n",
    "# Extract the answer\n",
    "if response.choices and len(response.choices) > 0:\n",
    "    answer = response.choices[0].message.content\n",
    "    print(f\"\\n✅ Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230ed0f",
   "metadata": {},
   "source": [
    "## List Vector Stores\n",
    "\n",
    "Llama Stack natively integrates with vector databases, using the `vector_stores` provider. In our case, we are using Milvus. The database was populated from the KubeFlow Pipeline (KFP) that you ran earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae78a5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://llama-stack-dist-service:8321/v1/vector_stores \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 1 vector store(s)\n",
      "\n",
      "Vector Store: competitor-docs\n",
      "  ID: vs_a8fba93a-3efe-4c36-a43d-0cb25edca697\n",
      "  Files: 11 total, 11 completed, 0 failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all vector stores\n",
    "vector_stores = list(client.vector_stores.list())\n",
    "\n",
    "if not vector_stores:\n",
    "    print(\"❌ No vector stores found!\")\n",
    "    print(\"Run the KFP pipeline to ingest documents first\")\n",
    "else:\n",
    "    print(f\"✅ Found {len(vector_stores)} vector store(s)\\n\")\n",
    "    \n",
    "    for vs in vector_stores:\n",
    "        vs_id = getattr(vs, 'id', None)\n",
    "        vs_name = getattr(vs, 'name', None)\n",
    "        file_counts = getattr(vs, 'file_counts', None)\n",
    "        \n",
    "        print(f\"Vector Store: {vs_name}\")\n",
    "        print(f\"  ID: {vs_id}\")\n",
    "        if file_counts:\n",
    "            print(f\"  Files: {file_counts.total} total, {file_counts.completed} completed, {file_counts.failed} failed\")\n",
    "        print()\n",
    "        \n",
    "        # Store for later use\n",
    "        target_vector_store = vs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497be82",
   "metadata": {},
   "source": [
    "## RAG Query: Search Vector Store\n",
    "\n",
    "Use `client.vector_stores.search()` to perform semantic search on the indexed documents. Llama Stack does a semantic similarity search in the background and fetches the relevant documents from the Milvus vector database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97c69249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://llama-stack-dist-service:8321/v1/vector_stores/vs_a8fba93a-3efe-4c36-a43d-0cb25edca697/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Query: What was the standalone Profit After Tax (PAT) for HDFC Bank in Q2 FY26?\n",
      "\n",
      "✅ Found 5 results:\n",
      "\n",
      "[1] Score: 0.9163\n",
      "    ; down 22% YoY\n",
      "- Net profit after tax of ₹ 1.8 bn compared to profit of ₹ 2.0 bn in the prior year\n",
      "- EPS of ₹ 2.52\n",
      "- Solvency Ratio at 210% as of September 30, 2025\n",
      "\n",
      "## Subsidiaries - Q2FY26 update - HDFC Securities Ltd\n",
      "\n",
      "- 94.11% stake held by the Bank as of September 30, 2025\n",
      "- 7.4 million customer...\n",
      "\n",
      "[2] Score: 0.9029\n",
      "     - 400 013. CIN:  L65920MH1994PLC080618\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## NEWS RELEASE\n",
      "\n",
      "HDFC Bank Ltd. HDFC Bank House, Senapati Bapat Marg, Lower Parel, Mumbai - 400 013. CIN:  L65920MH1994PLC080618\n",
      "\n",
      "herein below are in accordance with the accounting standards used in their standalone reporting under the applica...\n",
      "\n",
      "[3] Score: 0.8999\n",
      "     exchange &amp; derivatives revenue of ₹ 15.9 billion (₹ 14.6 billion in the corresponding quarter of the previous year), net trading and mark to market gain of ₹ 23.9 billion (₹ 2.9 billion in the corresponding quarter of the previous year) and miscellaneous income, including recoveries and dividen...\n",
      "\n",
      "[4] Score: 0.8986\n",
      "     image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Book value performance\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "30\n",
      "\n",
      "HDFC Bank Presentation Q2 FY2026\n",
      "\n",
      "* Book value per share for periods prior to Q2 Sep'25 are adjusted for bonus share issuance\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "APPENDIX\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Industry-wise distrib...\n",
      "\n",
      "[5] Score: 0.8981\n",
      "    UM at ₹ 3.6 tn up by 11% YoY\n",
      "- New Business Premium of ₹ 89 bn with new business margin at 24%\n",
      "- Value of new business for the quarter ₹ 10.1 bn\n",
      "- PAT of ₹ 4.5 bn up by 3% YoY\n",
      "- Solvency Ratio at 175% as of September 30, 2025\n",
      "- Embedded value at ₹ 595 bn improved 14% YoY\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Subsidia...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your search query\n",
    "query_text = \"What was the standalone Profit After Tax (PAT) for HDFC Bank in Q2 FY26?\"\n",
    "\n",
    "print(f\"🔍 Query: {query_text}\\n\")\n",
    "\n",
    "# Perform semantic search using the vector store API\n",
    "try:\n",
    "    search_response = client.vector_stores.search(\n",
    "        vector_store_id=target_vector_store.id,\n",
    "        query=query_text,\n",
    "        max_num_results=5\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    if search_response.data and len(search_response.data) > 0:\n",
    "        print(f\"✅ Found {len(search_response.data)} results:\\n\")\n",
    "        \n",
    "        for i, item in enumerate(search_response.data):\n",
    "            # Extract content\n",
    "            content = \"\"\n",
    "            if hasattr(item, 'content'):\n",
    "                if isinstance(item.content, list):\n",
    "                    content = \" \".join([\n",
    "                        c.text if hasattr(c, 'text') else str(c) \n",
    "                        for c in item.content\n",
    "                    ])\n",
    "                else:\n",
    "                    content = str(item.content)\n",
    "            \n",
    "            score = getattr(item, 'score', 'N/A')\n",
    "            \n",
    "            print(f\"[{i+1}] Score: {score:.4f}\")\n",
    "            print(f\"    {content[:300]}...\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"❌ No results found for your query\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Search failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cb2235",
   "metadata": {},
   "source": [
    "In the next notebook, you will implement a Retrieval Augemented Generation (RAG) pipeline with Llama Stack\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
